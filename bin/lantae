#!/usr/bin/env ruby

require 'json'
require 'net/http'
require 'uri'
require 'optparse'
require 'readline'
require 'tempfile'
require 'logger'
require 'fileutils'
require 'aws-sdk-secretsmanager'
require 'aws-sdk-bedrockruntime'
require_relative '../lib/ruby/mcp_manager'
require_relative '../lib/ruby/planning_agent'
require_relative '../lib/ruby/task_analyzer'
require_relative '../lib/ruby/execution_engine'
require_relative '../lib/ruby/task_database'
require_relative '../lib/ruby/auto_fixer'
require_relative '../lib/ruby/lsp/client'
require_relative '../lib/ruby/lsp/server_manager'
require_relative '../lib/ruby/lsp/auto_starter'

VERSION = '1.0.0'

class SecretManager
  def initialize(region = 'us-east-1', secret_name = 'lantae/api-keys')
    @region = region
    @secret_name = secret_name
    @client = nil
    @cached_secrets = {}
  end

  def get_api_key(provider)
    # First check environment variable
    env_key = "#{provider.upcase}_API_KEY"
    return ENV[env_key] if ENV[env_key]

    # Check cached secrets
    if @cached_secrets[provider]
      ENV[env_key] = @cached_secrets[provider]
      return @cached_secrets[provider]
    end

    # Fetch from AWS Secrets Manager
    begin
      init_client
      response = @client.get_secret_value(secret_id: @secret_name)
      secrets = JSON.parse(response.secret_string)
      
      # Cache all secrets and set environment variables
      secrets.each do |key, value|
        @cached_secrets[key] = value
        ENV["#{key.upcase}_API_KEY"] = value
      end
      
      @cached_secrets[provider]
    rescue Aws::SecretsManager::Errors::ResourceNotFoundException
      raise "AWS Secret '#{@secret_name}' not found. Create it with your API keys."
    rescue => e
      raise "Failed to retrieve API keys from AWS Secrets Manager: #{e.message}"
    end
  end

  private

  def init_client
    return if @client
    @client = Aws::SecretsManager::Client.new(region: @region)
  end
end

class ProviderManager
  def initialize(secret_manager, tool_manager = nil)
    @secret_manager = secret_manager
    @tool_manager = tool_manager
    @providers = {
      'ollama' => OllamaProvider.new,
      'openai' => OpenAIProvider.new(secret_manager),
      'anthropic' => AnthropicProvider.new(secret_manager),
      'bedrock' => BedrockProvider.new,
      'gemini' => GeminiProvider.new(secret_manager),
      'mistral' => MistralProvider.new(secret_manager),
      'perplexity' => PerplexityProvider.new(secret_manager)
    }
    @current_provider = 'ollama'
    @current_model = 'cogito:latest'
    
    # Set tool manager for Ollama provider
    @providers['ollama'].set_tool_manager(@tool_manager) if @tool_manager
  end

  attr_accessor :current_model, :current_provider

  def switch_provider(provider, model = nil)
    raise "Provider '#{provider}' not supported. Available: #{@providers.keys.join(', ')}" unless @providers[provider]
    
    @current_provider = provider
    if model
      @current_model = model
    else
      # Set default model for provider
      defaults = {
        'ollama' => 'cogito:latest',
        'openai' => 'gpt-4o',
        'anthropic' => 'claude-3-5-sonnet-20241022',
        'bedrock' => 'claude-3-sonnet',
        'gemini' => 'gemini-1.5-pro',
        'mistral' => 'mistral-large-latest',
        'perplexity' => 'llama-3.1-sonar-large-128k-online'
      }
      @current_model = defaults[provider]
    end
  end

  def chat(messages, options = {})
    provider = @providers[@current_provider]
    provider.chat(@current_model, messages, options)
  end

  def list_models
    provider = @providers[@current_provider]
    provider.list_models
  end

  def get_provider_info
    { provider: @current_provider, model: @current_model }
  end
end

class OllamaProvider
  def initialize(base_url = 'http://localhost:11434')
    @base_url = base_url
    @tool_manager = nil
  end

  def set_tool_manager(tool_manager)
    @tool_manager = tool_manager
  end

  def chat(model, messages, options = {})
    uri = URI("#{@base_url}/api/chat")
    http = Net::HTTP.new(uri.host, uri.port)
    http.read_timeout = 300
    http.open_timeout = 30
    
    # Add tool context to the system message
    enhanced_messages = messages.dup
    if @tool_manager && !enhanced_messages.empty?
      tools_context = @tool_manager.get_tools_context
      system_message = {
        role: 'system',
        content: "You are an AI assistant with access to various tools for file operations and system commands. #{tools_context}\n\nWhen you want to use a tool, include a TOOL_CALL in your response. You can make multiple tool calls in a single response. After each tool call, I will provide the result, and you can continue your response or make additional tool calls as needed.\n\nAlways explain what you're doing and why before using tools. Be helpful and thorough in your responses."
      }
      
      # Insert system message at the beginning if it doesn't exist, or merge with existing system message
      if enhanced_messages[0] && enhanced_messages[0][:role] == 'system'
        enhanced_messages[0][:content] = system_message[:content] + "\n\n" + enhanced_messages[0][:content]
      else
        enhanced_messages.unshift(system_message)
      end
    end
    
    request = Net::HTTP::Post.new(uri)
    request['Content-Type'] = 'application/json'
    request.body = {
      model: model,
      messages: enhanced_messages,
      stream: false,
      options: {
        temperature: (options[:temperature] || 0.1).to_f
      }
    }.to_json

    begin
      # Start spinner in a separate thread if not showing status already
      spinner_thread = nil
      unless options[:no_spinner]
        spinner_thread = start_spinner
      end
      
      response = http.request(request)
      
      # Stop spinner
      if spinner_thread
        spinner_thread.kill
        print "\r" + " " * 20 + "\r"  # Clear spinner line
      end
      
      data = JSON.parse(response.body)
      content = data['message']['content']
      
      # Process tool calls in the response
      content = process_tool_calls(content) if @tool_manager
      
      content
    rescue Errno::ECONNREFUSED
      if spinner_thread
        spinner_thread.kill
        print "\r" + " " * 20 + "\r"
      end
      raise 'Cannot connect to Ollama server. Make sure Ollama is running.'
    end
  end

  def process_tool_calls(content)
    processed_content = content.dup
    
    content.scan(/TOOL_CALL:\s*([^\n]+)/) do |tool_call_match|
      tool_call = tool_call_match[0].strip
      tool_name, *args = tool_call.split(' ')
      
      begin
        puts "\nüîß Executing tool: #{tool_name} #{args.join(' ')}"
        result = @tool_manager.execute_tool(tool_name, args.join(' '))
        
        # Replace the tool call with the result
        tool_call_line = "TOOL_CALL: #{tool_call}"
        replacement = "#{tool_call_line}\n\nTool Result:\n```\n#{result}\n```\n"
        processed_content = processed_content.gsub(tool_call_line, replacement)
        
        puts "‚úÖ Tool result: #{result[0..100]}#{result.length > 100 ? '...' : ''}"
      rescue => error
        error_msg = "Error executing #{tool_name}: #{error.message}"
        puts "‚ùå #{error_msg}"
        
        tool_call_line = "TOOL_CALL: #{tool_call}"
        replacement = "#{tool_call_line}\n\nTool Error:\n```\n#{error_msg}\n```\n"
        processed_content = processed_content.gsub(tool_call_line, replacement)
      end
    end
    
    processed_content
  end

  def list_models
    uri = URI("#{@base_url}/api/tags")
    http = Net::HTTP.new(uri.host, uri.port)
    http.read_timeout = 30
    http.open_timeout = 10
    
    begin
      response = http.get(uri)
      data = JSON.parse(response.body)
      (data['models'] || []).map { |m| m['name'] }
    rescue Errno::ECONNREFUSED
      raise 'Cannot connect to Ollama server. Make sure Ollama is running.'
    end
  end

  private

  def start_spinner
    Thread.new do
      spinner_chars = ['‚†ã', '‚†ô', '‚†π', '‚†∏', '‚†º', '‚†¥', '‚†¶', '‚†ß', '‚†á', '‚†è']
      i = 0
      while true
        print "\rü§ñ #{spinner_chars[i % spinner_chars.length]} Thinking..."
        sleep 0.1
        i += 1
      end
    end
  end
end

class OpenAIProvider
  def initialize(secret_manager)
    @secret_manager = secret_manager
  end

  def chat(model, messages, options = {})
    api_key = @secret_manager.get_api_key('openai')
    raise 'OpenAI API key not found in environment or AWS Secrets Manager' unless api_key

    uri = URI('https://api.openai.com/v1/chat/completions')
    http = Net::HTTP.new(uri.host, uri.port)
    http.use_ssl = true

    request = Net::HTTP::Post.new(uri)
    request['Authorization'] = "Bearer #{api_key}"
    request['Content-Type'] = 'application/json'
    request.body = {
      model: model,
      messages: messages,
      temperature: (options[:temperature] || 0.1).to_f,
      max_tokens: 4096
    }.to_json

    response = http.request(request)
    
    if response.code == '401'
      raise 'Invalid OpenAI API key. Check your credentials.'
    end

    data = JSON.parse(response.body)
    data['choices'][0]['message']['content']
  end

  def list_models
    %w[o1-preview o1-mini]
  end
end

class AnthropicProvider
  def initialize(secret_manager)
    @secret_manager = secret_manager
  end

  def chat(model, messages, options = {})
    api_key = @secret_manager.get_api_key('anthropic')
    raise 'Anthropic API key not found in environment or AWS Secrets Manager' unless api_key

    uri = URI('https://api.anthropic.com/v1/messages')
    http = Net::HTTP.new(uri.host, uri.port)
    http.use_ssl = true

    request = Net::HTTP::Post.new(uri)
    request['x-api-key'] = api_key
    request['anthropic-version'] = '2023-06-01'
    request['Content-Type'] = 'application/json'
    request.body = {
      model: model,
      max_tokens: 4096,
      temperature: (options[:temperature] || 0.1).to_f,
      messages: messages
    }.to_json

    response = http.request(request)
    
    if response.code == '401'
      raise 'Invalid Anthropic API key. Check your credentials.'
    end

    data = JSON.parse(response.body)
    data['content'][0]['text']
  end

  def list_models
    %w[claude-3-5-sonnet-20241022 claude-3-5-haiku-20241022 claude-3-opus-20240229 claude-3-sonnet-20240229 claude-3-haiku-20240307]
  end
end

class GeminiProvider
  def initialize(secret_manager)
    @secret_manager = secret_manager
  end

  def chat(model, messages, options = {})
    api_key = @secret_manager.get_api_key('gemini')
    raise 'Gemini API key not found in environment or AWS Secrets Manager' unless api_key

    # Convert messages to Gemini format
    contents = messages.map do |msg|
      {
        role: msg[:role] == 'assistant' ? 'model' : 'user',
        parts: [{ text: msg[:content] }]
      }
    end

    uri = URI("https://generativelanguage.googleapis.com/v1beta/models/#{model}:generateContent?key=#{api_key}")
    http = Net::HTTP.new(uri.host, uri.port)
    http.use_ssl = true

    request = Net::HTTP::Post.new(uri)
    request['Content-Type'] = 'application/json'
    request.body = {
      contents: contents,
      generationConfig: {
        temperature: (options[:temperature] || 0.1).to_f,
        maxOutputTokens: 4096
      }
    }.to_json

    response = http.request(request)
    
    if response.body.include?('API_KEY_INVALID')
      raise 'Invalid Gemini API key. Check your credentials.'
    end

    data = JSON.parse(response.body)
    data['candidates'][0]['content']['parts'][0]['text']
  end

  def list_models
    %w[gemini-1.5-pro gemini-1.5-flash gemini-1.0-pro]
  end
end

class MistralProvider
  def initialize(secret_manager)
    @secret_manager = secret_manager
  end

  def chat(model, messages, options = {})
    api_key = @secret_manager.get_api_key('mistral')
    raise 'Mistral API key not found in environment or AWS Secrets Manager' unless api_key

    uri = URI('https://api.mistral.ai/v1/chat/completions')
    http = Net::HTTP.new(uri.host, uri.port)
    http.use_ssl = true

    request = Net::HTTP::Post.new(uri)
    request['Authorization'] = "Bearer #{api_key}"
    request['Content-Type'] = 'application/json'
    request.body = {
      model: model,
      messages: messages,
      temperature: (options[:temperature] || 0.1).to_f,
      max_tokens: 4096
    }.to_json

    response = http.request(request)
    
    if response.code == '401'
      raise 'Invalid Mistral API key. Check your credentials.'
    end

    data = JSON.parse(response.body)
    data['choices'][0]['message']['content']
  end

  def list_models
    %w[mistral-large-latest mistral-medium-latest mistral-small-latest open-mistral-7b open-mixtral-8x7b open-mixtral-8x22b]
  end
end

class PerplexityProvider
  def initialize(secret_manager)
    @secret_manager = secret_manager
  end

  def chat(model, messages, options = {})
    api_key = @secret_manager.get_api_key('perplexity')
    raise 'Perplexity API key not found in environment or AWS Secrets Manager' unless api_key

    uri = URI('https://api.perplexity.ai/chat/completions')
    http = Net::HTTP.new(uri.host, uri.port)
    http.use_ssl = true

    request = Net::HTTP::Post.new(uri)
    request['Authorization'] = "Bearer #{api_key}"
    request['Content-Type'] = 'application/json'
    request.body = {
      model: model,
      messages: messages,
      temperature: (options[:temperature] || 0.1).to_f,
      max_tokens: 4096
    }.to_json

    response = http.request(request)
    
    if response.code == '401'
      raise 'Invalid Perplexity API key. Check your credentials.'
    end

    data = JSON.parse(response.body)
    data['choices'][0]['message']['content']
  end

  def list_models
    %w[llama-3.1-sonar-large-128k-online llama-3.1-sonar-small-128k-online llama-3.1-sonar-large-128k-chat llama-3.1-sonar-small-128k-chat llama-3.1-8b-instruct llama-3.1-70b-instruct]
  end
end

class BedrockProvider
  def initialize(region = 'us-east-1')
    @region = region
    @client = nil
  end

  def chat(model, messages, options = {})
    init_client

    model_map = {
      'claude-3-sonnet' => 'anthropic.claude-3-sonnet-20240229-v1:0',
      'claude-3-haiku' => 'anthropic.claude-3-haiku-20240307-v1:0',
      'claude-3-opus' => 'anthropic.claude-3-opus-20240229-v1:0',
      'claude-3-5-sonnet' => 'anthropic.claude-3-5-sonnet-20240620-v1:0',
      'claude-3-5-haiku' => 'anthropic.claude-3-5-haiku-20241022-v1:0',
      'titan-text-g1-large' => 'amazon.titan-text-lite-v1',
      'titan-text-g1-express' => 'amazon.titan-text-express-v1'
    }

    bedrock_model_id = model_map[model] || model

    if bedrock_model_id.include?('anthropic.claude')
      body = {
        anthropic_version: 'bedrock-2023-05-31',
        max_tokens: 4096,
        temperature: (options[:temperature] || 0.1).to_f,
        messages: messages
      }.to_json
    elsif bedrock_model_id.include?('amazon.titan')
      prompt = messages.map { |m| "#{m[:role]}: #{m[:content]}" }.join("\n")
      body = {
        inputText: prompt,
        textGenerationConfig: {
          temperature: (options[:temperature] || 0.1).to_f,
          maxTokenCount: 4096
        }
      }.to_json
    else
      raise "Unsupported model format: #{bedrock_model_id}"
    end

    response = @client.invoke_model({
      model_id: bedrock_model_id,
      body: body
    })

    response_body = JSON.parse(response.body.read)

    if bedrock_model_id.include?('anthropic.claude')
      response_body['content'][0]['text']
    elsif bedrock_model_id.include?('amazon.titan')
      response_body['results'][0]['outputText']
    end
  rescue Aws::Errors::MissingCredentialsError
    raise 'AWS credentials not found. Configure AWS CLI or environment variables.'
  end

  def list_models
    %w[claude-3-5-sonnet claude-3-5-haiku claude-3-sonnet claude-3-haiku claude-3-opus titan-text-g1-large titan-text-g1-express]
  end

  private

  def init_client
    return if @client
    @client = Aws::BedrockRuntime::Client.new(region: @region)
  end
end

class ToolManager
  def initialize(mcp_manager = nil, lsp_client = nil)
    @mcp_manager = mcp_manager
    @lsp_client = lsp_client
    @tools_used = []
    @files_accessed = []
  end
  
  attr_reader :tools_used, :files_accessed
  
  def execute_tool(tool_name, args)
    # Track tool usage for LSP auto-start
    @tools_used << tool_name unless @tools_used.include?(tool_name)
    
    # Track file access for code intelligence
    if %w[cat write_file edit_file create_file].include?(tool_name)
      file_path = args.split(' ').first
      @files_accessed << file_path if file_path
    end
    
    # Auto-start LSP if beneficial and not running
    auto_start_lsp_if_beneficial
    
    # Check if this is an MCP tool (format: server__tool)
    if tool_name.include?('__') && @mcp_manager
      return execute_mcp_tool(tool_name, args)
    end
    
    case tool_name
    when 'bash'
      execute_bash(args)
    when 'ruby'
      execute_ruby(args)
    when 'python'
      execute_python(args)
    when 'ls'
      list_files(args.empty? ? '.' : args)
    when 'cat'
      read_file(args)
    when 'pwd'
      Dir.pwd
    when 'git'
      execute_bash("git #{args}")
    when 'bundle'
      execute_bash("bundle #{args}")
    when 'write_file'
      write_file(args)
    when 'edit_file'
      edit_file(args)
    when 'create_file'
      create_file(args)
    when 'delete_file'
      delete_file(args)
    when 'mkdir'
      make_directory(args)
    when 'find'
      find_files(args)
    else
      raise "Tool '#{tool_name}' not found. Available tools: #{list_available_tools.join(', ')}"
    end
  end

  def get_tools_context
    <<~CONTEXT
      Available tools you can use:
      - bash <command>: Execute bash commands
      - cat <file>: Read file contents
      - write_file <file> <content>: Write content to a file
      - edit_file <file> <line_number> <new_content>: Edit a specific line in a file
      - create_file <file> [content]: Create a new file with optional content
      - delete_file <file>: Delete a file
      - mkdir <directory>: Create a directory
      - ls [directory]: List files in directory
      - find <pattern>: Find files matching pattern
      - pwd: Get current directory
      - git <command>: Execute git commands
      - bundle <command>: Execute bundle commands
      - ruby <code>: Execute Ruby code
      - python <code>: Execute Python code

      To use a tool, format your response like this:
      TOOL_CALL: tool_name arguments
      For example:
      TOOL_CALL: cat Gemfile
      TOOL_CALL: write_file hello.txt Hello World!
      TOOL_CALL: edit_file main.rb 5 puts "Updated line"
    CONTEXT
  end

  def list_available_tools
    builtin_tools = %w[bash ruby python ls cat pwd git bundle write_file edit_file create_file delete_file mkdir find]
    
    if @mcp_manager
      mcp_tools = @mcp_manager.get_available_tools.keys
      builtin_tools + mcp_tools
    else
      builtin_tools
    end
  end

  private

  def auto_start_lsp_if_beneficial
    # Only auto-start if LSP client is not already available
    return if @lsp_client
    
    # Check if LSP auto-start would be beneficial based on tool usage
    context = {
      current_directory: Dir.pwd,
      tools_used: @tools_used,
      files_accessed: @files_accessed
    }
    
    # Use AutoStarter to determine if LSP should be started
    if Lantae::LSP::AutoStarter.auto_start_if_beneficial(context)
      # Try to connect client if server started successfully
      begin
        if Lantae::LSP::ServerManager.running?
          @lsp_client = Lantae::LSP::Client.new
          @lsp_client.start
        end
      rescue => e
        # Silently handle LSP connection errors - don't interrupt tool execution
        @lsp_client = nil
      end
    end
  rescue => e
    # Silently handle any auto-start errors - don't interrupt tool execution
  end

  def execute_mcp_tool(tool_name, args)
    puts "Executing MCP tool: #{tool_name}"
    
    begin
      # Parse arguments for MCP tool call
      arguments = parse_mcp_arguments(args)
      
      result = @mcp_manager.call_mcp_tool(tool_name, arguments)
      
      if result[:success]
        format_mcp_result(result[:result])
      else
        "MCP Tool Error: #{result[:error][:message] || 'Unknown error'}"
      end
      
    rescue => e
      puts "MCP tool execution failed: #{e.message}"
      "Error executing MCP tool #{tool_name}: #{e.message}"
    end
  end
  
  def parse_mcp_arguments(args_string)
    # Simple argument parsing - could be enhanced for complex structures
    return {} if args_string.nil? || args_string.strip.empty?
    
    # Try to parse as JSON first
    begin
      JSON.parse(args_string)
    rescue JSON::ParserError
      # Fallback to simple key=value parsing
      args = {}
      args_string.split(' ').each do |pair|
        if pair.include?('=')
          key, value = pair.split('=', 2)
          args[key] = value
        end
      end
      args
    end
  end
  
  def format_mcp_result(result)
    if result.is_a?(Hash) && result[:content]
      # Handle MCP content format
      content_parts = result[:content].map do |item|
        case item[:type]
        when 'text'
          item[:text]
        when 'image'
          "[Image: #{item[:data] ? 'embedded' : item[:url]}]"
        else
          item.to_s
        end
      end
      content_parts.join("\n")
    else
      result.to_s
    end
  end

  def execute_bash(command)
    result = `#{command} 2>&1`
    $?.success? ? result : "Error: #{result}"
  rescue => e
    "Error: #{e.message}"
  end

  def execute_ruby(code)
    eval(code).to_s
  rescue => e
    "Error: #{e.message}"
  end

  def execute_python(code)
    temp_file = Tempfile.new(['lantae', '.py'])
    temp_file.write(code)
    temp_file.close
    
    result = `python3 #{temp_file.path} 2>&1`
    temp_file.unlink
    result
  rescue => e
    "Error: #{e.message}"
  end

  def list_files(dir)
    Dir.entries(dir).join("\n")
  rescue => e
    "Error: #{e.message}"
  end

  def read_file(file_path)
    File.read(file_path)
  rescue => e
    "Error: #{e.message}"
  end

  def write_file(args)
    parts = args.split(' ', 2)
    file_path = parts[0]
    content = parts[1] || ''
    
    File.write(file_path, content)
    
    # Notify LSP about file change
    if @lsp_client
      begin
        @lsp_client.open_file(file_path, content)
        # Get initial diagnostics
        @lsp_client.get_code_actions(file_path, 0, 0, 0, 0)
      rescue => e
        # LSP errors shouldn't break file operations
      end
    end
    
    "File #{file_path} written successfully"
  rescue => e
    "Error: #{e.message}"
  end

  def edit_file(args)
    parts = args.split(' ', 3)
    file_path = parts[0]
    line_number = parts[1].to_i
    new_content = parts[2] || ''
    
    lines = File.readlines(file_path)
    
    if line_number > 0 && line_number <= lines.length
      lines[line_number - 1] = new_content + "\n"
      File.write(file_path, lines.join)
      "Line #{line_number} in #{file_path} edited successfully"
    else
      "Error: Line number #{line_number} out of range"
    end
  rescue => e
    "Error: #{e.message}"
  end

  def create_file(args)
    parts = args.split(' ', 2)
    file_path = parts[0]
    content = parts[1] || ''
    
    if File.exist?(file_path)
      "Error: File #{file_path} already exists"
    else
      File.write(file_path, content)
      
      # Notify LSP about new file
      if @lsp_client
        begin
          @lsp_client.open_file(file_path, content)
          # For Lantae-generated files, offer AI enhancements
          if content.include?('Generated by Lantae AI')
            @lsp_client.get_code_actions(file_path, 0, 0, 0, 0)
          end
        rescue => e
          # LSP errors shouldn't break file operations
        end
      end
      
      "File #{file_path} created successfully"
    end
  rescue => e
    "Error: #{e.message}"
  end

  def delete_file(file_path)
    File.delete(file_path)
    "File #{file_path} deleted successfully"
  rescue => e
    "Error: #{e.message}"
  end

  def make_directory(dir_path)
    require 'fileutils'
    FileUtils.mkdir_p(dir_path)
    "Directory #{dir_path} created successfully"
  rescue => e
    "Error: #{e.message}"
  end

  def find_files(pattern)
    result = `find . -name "#{pattern}" 2>&1`
    result.empty? ? 'No files found' : result
  rescue => e
    "Error: #{e.message}"
  end
end

def send_single_prompt(prompt, options)
  secret_manager = SecretManager.new(options[:region], options[:secret])
  
  # Initialize MCP if enabled
  mcp_manager = nil
  if options[:enable_mcp]
    mcp_manager = MCPManager.new
    if mcp_manager.load_server_configs(options[:mcp_config])
      mcp_manager.discover_servers
      mcp_manager.connect_all_servers
    else
      mcp_manager = nil
    end
  end
  
  tool_manager = ToolManager.new(mcp_manager, nil)  # No LSP in non-REPL mode
  provider_manager = ProviderManager.new(secret_manager, tool_manager)
  
  if options[:provider] != 'ollama'
    provider_manager.switch_provider(options[:provider], options[:model])
  else
    provider_manager.current_model = options[:model]
  end
  
  # Handle agent mode
  if options[:agent_mode]
    execute_agent_task(prompt, provider_manager, tool_manager, options)
  else
    response = provider_manager.chat([{ role: 'user', content: prompt }], options)
    puts "#{response}"
  end
rescue => e
  puts "Error: #{e.message}"
  exit 1
end

def execute_agent_task(task_description, provider_manager, tool_manager, options)
  puts "#{"\e[96m"}ü§ñ Agent Mode: Planning and executing task...#{"\e[0m"}\n"
  
  # Initialize agent components
  task_analyzer = TaskAnalyzer.new
  task_database = TaskDatabase.new
  
  planning_agent = PlanningAgent.new(
    provider_manager, 
    tool_manager,
    task_analyzer: task_analyzer,
    logger: Logger.new(STDOUT)
  )
  
  execution_engine = ExecutionEngine.new(
    provider_manager,
    tool_manager,
    logger: Logger.new(STDOUT)
  )
  
  # Plan the task
  puts "#{"\e[93m"}üìã Creating execution plan...#{"\e[0m"}"
  task = planning_agent.plan_task(task_description)
  
  # Display the plan
  puts "\n#{"\e[92m"}üìä Execution Plan:#{"\e[0m"}"
  puts task.to_tree_string
  
  # Ask for confirmation unless auto-accept
  unless options[:auto_accept]
    print "\n#{"\e[94m"}Proceed with execution? (y/n): #{"\e[0m"}"
    response = gets.chomp.downcase
    unless response == 'y' || response == 'yes'
      puts "#{"\e[91m"}Execution cancelled.#{"\e[0m"}"
      return
    end
  end
  
  # Execute the plan
  puts "\n#{"\e[93m"}‚öôÔ∏è  Executing plan...#{"\e[0m"}"
  success = planning_agent.execute_plan(task, execution_engine)
  
  # Record execution results
  if task.execution_result
    task_database.record_task_execution(task, task.execution_result)
  end
  
  # Display results
  puts "\n#{"\e[92m"}üìä Execution Results:#{"\e[0m"}"
  puts task.to_tree_string
  
  if success
    puts "\n#{"\e[92m"}‚úÖ Task completed successfully!#{"\e[0m"}"
  else
    puts "\n#{"\e[91m"}‚ùå Task failed. Check the execution tree for details.#{"\e[0m"}"
    
    # Show optimization suggestions
    suggestions = task_database.suggest_prompt_improvements(task_description)
    if suggestions.any?
      puts "\n#{"\e[93m"}üí° Suggestions for improvement:#{"\e[0m"}"
      suggestions.each do |suggestion|
        puts "  - #{suggestion[:recommendation]} (#{suggestion[:reason]})"
      end
    end
  end
end

def print_banner
  puts <<~BANNER
    #{"\e[96m"}
    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
    ‚ïë  #{"\e[95m"}‚ñà‚ñà‚ïó      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó#{"\e[96m"}  ‚ïë
    ‚ïë  #{"\e[95m"}‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù#{"\e[96m"}  ‚ïë
    ‚ïë  #{"\e[95m"}‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó#{"\e[96m"}    ‚ïë
    ‚ïë  #{"\e[95m"}‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù#{"\e[96m"}    ‚ïë
    ‚ïë  #{"\e[95m"}‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó#{"\e[96m"}  ‚ïë
    ‚ïë  #{"\e[95m"}‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù   ‚ïö‚ïê‚ïù   ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù#{"\e[96m"}  ‚ïë
    ‚ïë                                                              ‚ïë
    ‚ïë  #{"\e[93m"}üöÄ Multi-Provider LLM Interface v#{VERSION}#{"\e[96m"}                    ‚ïë
    ‚ïë  #{"\e[92m"}‚ö° Powered by Cogito Reasoning Model#{"\e[96m"}                      ‚ïë
    ‚ïë  #{"\e[94m"}üîó Ollama ‚Ä¢ OpenAI ‚Ä¢ Anthropic ‚Ä¢ Bedrock & More#{"\e[96m"}          ‚ïë
    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    #{"\e[0m"}
  BANNER
end

def setup_autocomplete(provider_manager, tool_manager, mcp_manager = nil)
  # Define slash commands
  slash_commands = %w[help model provider models tool tools mcp clear info env]
  
  # Define providers
  providers = %w[ollama openai anthropic bedrock gemini mistral perplexity]
  
  # Get available models (cached for performance)
  models = []
  begin
    models = provider_manager.list_models
  rescue => e
    # Silently fail if models can't be fetched
  end
  
  # Get available tools
  tools = tool_manager.list_available_tools
  
  # Get MCP subcommands
  mcp_subcommands = %w[status health reload tools]
  
  # Completion proc
  comp = proc do |input|
    completions = []
    
    # Handle slash commands
    if input.start_with?('/')
      # Extract command and args
      parts = input[1..-1].split(' ', 2)
      command = parts[0] || ''
      args = parts[1] || ''
      
      if parts.length == 1
        # Complete slash command itself
        completions = slash_commands.select { |cmd| cmd.start_with?(command) }.map { |cmd| "/#{cmd}" }
      else
        # Complete command arguments
        case command
        when 'provider'
          if args.split(' ').length == 1
            completions = providers.select { |p| p.start_with?(args) }.map { |p| "/provider #{p}" }
          elsif args.split(' ').length == 2
            provider_name = args.split(' ')[0]
            model_start = args.split(' ')[1]
            completions = models.select { |m| m.start_with?(model_start) }.map { |m| "/provider #{provider_name} #{m}" }
          end
        when 'model'
          completions = models.select { |m| m.start_with?(args) }.map { |m| "/model #{m}" }
        when 'tool'
          if args.split(' ', 2).length == 1
            completions = tools.select { |t| t.start_with?(args) }.map { |t| "/tool #{t}" }
          else
            tool_name = args.split(' ', 2)[0]
            file_arg = args.split(' ', 2)[1]
            # For file-based tools, complete file paths
            if %w[cat write_file edit_file create_file delete_file].include?(tool_name)
              completions = Dir.glob("#{file_arg}*").map { |f| "/tool #{tool_name} #{f}" }
            end
          end
        when 'mcp'
          if mcp_manager && args.split(' ').length == 1
            completions = mcp_subcommands.select { |sub| sub.start_with?(args) }.map { |sub| "/mcp #{sub}" }
          end
        end
      end
    else
      # Non-slash command completions (file paths)
      completions = Dir.glob("#{input}*")
    end
    
    completions
  end
  
  Readline.completion_proc = comp
  Readline.completion_append_character = ' '
end

def start_repl(options)
  secret_manager = SecretManager.new(options[:region], options[:secret])
  
  # Initialize MCP if enabled
  mcp_manager = nil
  if options[:enable_mcp]
    mcp_manager = MCPManager.new
    if mcp_manager.load_server_configs(options[:mcp_config])
      mcp_manager.discover_servers
      mcp_manager.connect_all_servers
    else
      mcp_manager = nil
    end
  end
  
  # Initialize LSP client for enhanced code support
  lsp_client = nil
  if options[:enable_lsp]
    begin
      # Smart auto-start LSP server if it would be beneficial
      context = {
        current_directory: Dir.pwd,
        tools_used: [],
        files_accessed: []
      }
      
      if Lantae::LSP::AutoStarter.auto_start_if_beneficial(context.merge(port: options[:lsp_port]))
        puts "‚úÖ LSP server available"
      end
      
      # Connect client if server is available
      if Lantae::LSP::ServerManager.running?
        lsp_client = Lantae::LSP::Client.new
        if lsp_client.start
          puts "üîå Connected to LSP server for enhanced code intelligence"
        else
          puts "‚ö†Ô∏è  Failed to connect to LSP server"
          lsp_client = nil
        end
      end
    rescue => e
      puts "‚ö†Ô∏è  LSP initialization error: #{e.message}"
      lsp_client = nil
    end
  end
  
  tool_manager = ToolManager.new(mcp_manager, lsp_client)
  provider_manager = ProviderManager.new(secret_manager, tool_manager)
  conversation = []
  
  if options[:provider] != 'ollama'
    provider_manager.switch_provider(options[:provider], options[:model])
  else
    provider_manager.current_model = options[:model]
  end
  
  print_banner unless options[:no_banner]
  
  info = provider_manager.get_provider_info
  puts "#{"\e[96m"}Provider: #{"\e[93m"}#{info[:provider]}#{"\e[96m"} | Model: #{"\e[92m"}#{info[:model]}#{"\e[0m"}"
  
  # Display active modes
  modes = []
  modes << "#{"\e[93m"}Auto-Accept#{"\e[0m"}" if options[:auto_accept]
  modes << "#{"\e[94m"}Planning Mode#{"\e[0m"}" if options[:planning_mode]
  modes << "#{"\e[95m"}Agent Mode#{"\e[0m"}" if options[:agent_mode]
  puts "#{"\e[96m"}Active Modes: #{modes.join(', ')}#{"\e[0m"}" unless modes.empty?
  
  puts "#{"\e[90m"}Type \"/help\" for commands, \"exit\" or \"quit\" to end#{"\e[0m"}"
  puts

  begin
    models = provider_manager.list_models
    if models.empty?
      puts '‚ö†Ô∏è  No models found.'
    elsif !models.include?(provider_manager.current_model)
      puts "‚ö†Ô∏è  Model \"#{provider_manager.current_model}\" not found. Available models:"
      models.first(10).each { |m| puts "  - #{m}" }
      puts "  ... and #{models.length - 10} more" if models.length > 10
      puts
    end
  rescue => e
    puts "Error checking models: #{e.message}"
  end
  
  # Set up autocomplete
  setup_autocomplete(provider_manager, tool_manager, mcp_manager)

  loop do
    begin
      input = Readline.readline('> ', true)
      break if input.nil? || input.strip == 'exit' || input.strip == 'quit'
      
      input = input.strip
      next if input.empty?
      
      if input.start_with?('/')
        handle_slash_command(input, provider_manager, tool_manager, conversation, mcp_manager, options)
        next
      end
      
      # Handle planning mode
      if options[:planning_mode] && !input.downcase.include?('execute') && !input.downcase.include?('proceed')
        input = "Please create a detailed plan for: #{input}. Break it down into clear steps and ask for confirmation before proceeding."
      end
      
      conversation << { role: 'user', content: input }
      
      response = provider_manager.chat(conversation, options)
      conversation << { role: 'assistant', content: response }
      puts "#{response}\n\n"
      
      # Auto-accept mode handling
      if options[:auto_accept] && (response.downcase.include?('would you like') || response.downcase.include?('shall i') || response.downcase.include?('proceed'))
        puts "#{"\e[93m"}[AUTO-ACCEPT] Automatically confirming action...#{"\e[0m"}\n"
        conversation << { role: 'user', content: 'Yes, please proceed.' }
        
        auto_response = provider_manager.chat(conversation, options)
        conversation << { role: 'assistant', content: auto_response }
        puts "#{auto_response}\n\n"
      end
      
    rescue Interrupt
      puts "\nGoodbye!"
      break
    rescue => e
      puts "Error: #{e.message}"
    end
  end
end

def handle_slash_command(input, provider_manager, tool_manager, conversation, mcp_manager = nil, options = {})
  parts = input[1..-1].split(' ')
  command = parts[0]
  args = parts[1..-1].join(' ')

  case command
  when 'help'
    puts <<~HELP
      Available commands:
        /model <name>       - Switch to a different model
        /provider <name>    - Switch provider (ollama, openai, anthropic, bedrock, gemini, mistral, perplexity)
        /lsp <subcommand>   - LSP commands (start, stop, status, analyze, format)
        /models             - List available models for current provider
        /tool <name> <args> - Execute a local tool
        /tools              - List available tools
        /mcp <subcommand>   - MCP server management (status, health, tools, reload)
        /agent <subcommand> - Agent management (plan, execute, report, history)
        /clear              - Clear conversation history
        /info               - Show current provider and model info
        /env                - Show environment variables status
        /help               - Show this help message
    HELP

  when 'model'
    if args.empty?
      puts 'Usage: /model <model-name>'
    else
      provider_manager.current_model = args
      puts "Switched to model: #{args}"
    end

  when 'provider'
    if args.empty?
      puts 'Usage: /provider <provider-name> [model]'
    else
      provider, model = args.split(' ', 2)
      provider_manager.switch_provider(provider, model)
      info = provider_manager.get_provider_info
      puts "Switched to provider: #{info[:provider]}, model: #{info[:model]}"
    end

  when 'models'
    models = provider_manager.list_models
    puts 'Available models:'
    models.each { |m| puts "  - #{m}" }

  when 'tool'
    if args.empty?
      puts 'Usage: /tool <tool-name> <arguments>'
    else
      tool_name, *tool_args = args.split(' ')
      result = tool_manager.execute_tool(tool_name, tool_args.join(' '))
      puts result
    end

  when 'tools'
    tools = tool_manager.list_available_tools
    puts 'Available tools:'
    tools.each { |t| puts "  - #{t}" }

  when 'clear'
    conversation.clear
    puts 'Conversation cleared.'

  when 'info'
    info = provider_manager.get_provider_info
    puts "Provider: #{info[:provider]}"
    puts "Model: #{info[:model]}"

  when 'mcp'
    handle_mcp_command(args, mcp_manager)

  when 'lsp'
    handle_lsp_command(args, tool_manager.instance_variable_get(:@lsp_client), options)

  when 'agent'
    handle_agent_command(args, provider_manager, tool_manager, options)

  when 'env'
    puts 'Environment Variables Status:'
    %w[openai anthropic gemini mistral perplexity].each do |provider|
      key = "#{provider.upcase}_API_KEY"
      puts "#{key}: #{ENV[key] ? '‚úì Set' : '‚úó Not set'}"
    end
    puts "AWS_PROFILE: #{ENV['AWS_PROFILE'] || 'default'}"
    puts "AWS_REGION: #{ENV['AWS_REGION'] || 'not set'}"

  else
    puts "Unknown command: /#{command}. Type /help for available commands."
  end
rescue => e
  puts "Error: #{e.message}"
end

def handle_lsp_command(args, lsp_client, options = {})
  parts = args.split(' ')
  subcommand = parts.first
  
  case subcommand
  when 'start'
    port = parts[1]&.to_i || options[:lsp_port] || 7777
    if Lantae::LSP::ServerManager.start(port: port)
      puts "‚úÖ LSP server started on port #{port}"
    else
      puts "‚ùå Failed to start LSP server"
    end
    
  when 'stop'
    if Lantae::LSP::ServerManager.stop
      puts "‚úÖ LSP server stopped"
    else
      puts "‚ùå Failed to stop LSP server"
    end
    
  when 'restart'
    port = parts[1]&.to_i || options[:lsp_port] || 7777
    if Lantae::LSP::ServerManager.restart(port: port)
      puts "‚úÖ LSP server restarted on port #{port}"
    else
      puts "‚ùå Failed to restart LSP server"
    end
    
  when 'status'
    Lantae::LSP::ServerManager.status
    
    if lsp_client
      puts "\nClient Status: #{lsp_client.instance_variable_get(:@running) ? '‚úÖ Connected' : '‚ùå Disconnected'}"
      if lsp_client.capabilities.any?
        puts "Client Capabilities:"
        lsp_client.capabilities.each do |cap, value|
          puts "  - #{cap}: #{value ? '‚úì' : '‚úó'}"
        end
      end
    else
      puts "\nClient Status: ‚ùå Not initialized"
    end
    
  when 'analyze'
    if lsp_client.nil?
      puts "‚ùå LSP client not connected. Use /lsp start first."
      return
    end
    
    file_path = parts[1]
    if file_path.nil? || file_path.empty?
      puts "Usage: /lsp analyze <file_path>"
      return
    end
    
    if File.exist?(file_path)
      content = File.read(file_path)
      lsp_client.open_file(file_path, content)
      # Wait a moment for diagnostics
      sleep(0.5)
      puts "‚úÖ File analyzed: #{file_path}"
    else
      puts "‚ùå File not found: #{file_path}"
    end
    
  when 'format'
    if lsp_client.nil?
      puts "‚ùå LSP client not connected. Use /lsp start first."
      return
    end
    
    file_path = parts[1]
    if file_path.nil? || file_path.empty?
      puts "Usage: /lsp format <file_path>"
      return
    end
    
    if File.exist?(file_path)
      content = File.read(file_path)
      lsp_client.open_file(file_path, content)
      edits = lsp_client.format_document(file_path)
      
      if edits && !edits.empty?
        # Apply formatting edits
        edits.each do |edit|
          # Simple implementation - just replace the whole content
          if edit['newText']
            File.write(file_path, edit['newText'])
            puts "‚úÖ File formatted: #{file_path}"
          end
        end
      else
        puts "‚ÑπÔ∏è  No formatting changes needed"
      end
    else
      puts "‚ùå File not found: #{file_path}"
    end
    
  when 'complete'
    puts "‚ÑπÔ∏è  Interactive completion not yet implemented. Use code completion in your editor."
    
  else
    puts <<~HELP
      LSP Commands:
        /lsp start [port]        - Start LSP server
        /lsp stop                - Stop LSP server  
        /lsp restart [port]      - Restart LSP server
        /lsp status              - Show server and client status
        /lsp analyze <file>      - Analyze a file for issues
        /lsp format <file>       - Format a file
        /lsp complete            - Get completions (coming soon)
    HELP
  end
end

def handle_mcp_command(args, mcp_manager)
  unless mcp_manager
    puts "MCP not enabled. Use --enable-mcp flag to enable MCP support."
    return
  end
  
  parts = args.split(' ', 2)
  subcommand = parts[0]
  
  case subcommand
  when 'status'
    status = mcp_manager.get_server_status
    
    puts "MCP Server Status:"
    puts "  Discovered: #{status[:discovered]}"
    puts "  Connected: #{status[:connected]}"
    puts
    
    status[:servers].each do |server_name, server_status|
      puts "  #{server_name}:"
      puts "    Status: #{server_status[:status]}"
      puts "    Transport: #{server_status[:transport]}"
      puts "    Tools: #{server_status[:tools_count]}"
      puts "    Resources: #{server_status[:resources_count]}"
      
      if server_status[:last_error]
        puts "    Last Error: #{server_status[:last_error]}"
      end
      
      puts
    end
    
  when 'health'
    health = mcp_manager.health_check
    
    puts "MCP Health Check Results:"
    puts "  Total Servers: #{health[:total_servers]}"
    puts "  Healthy: #{health[:healthy_servers]}"
    puts "  Unhealthy: #{health[:unhealthy_servers]}"
    puts "  Health Rate: #{health[:health_rate]}%"
    
    unless health[:issues].empty?
      puts "\n  Issues:"
      health[:issues].each do |issue|
        puts "    #{issue[:server]}: #{issue[:error]}"
      end
    end
    
  when 'reload'
    puts "Reloading MCP configuration..."
    if mcp_manager.reload_configuration
      puts "MCP configuration reloaded successfully."
      
      status = mcp_manager.get_server_status
      puts "Connected to #{status[:connected]} servers."
    else
      puts "Failed to reload MCP configuration."
    end
    
  when 'tools'
    tools = mcp_manager.get_available_tools
    
    if tools.empty?
      puts "No MCP tools available."
    else
      puts "Available MCP Tools:"
      tools.each do |qualified_name, tool_info|
        puts "  #{qualified_name}"
        puts "    Server: #{tool_info[:server]}"
        
        if tool_info[:info][:description]
          puts "    Description: #{tool_info[:info][:description]}"
        end
        
        if tool_info[:info][:inputSchema]
          puts "    Parameters: #{tool_info[:info][:inputSchema][:properties]&.keys&.join(', ') || 'None'}"
        end
        
        puts
      end
    end
    
  when '', nil
    puts "MCP subcommands: status, health, reload, tools"
    
  else
    puts "Unknown MCP subcommand: #{subcommand}. Available: status, health, reload, tools"
  end
  
rescue => e
  puts "MCP command error: #{e.message}"
end

def handle_agent_command(args, provider_manager, tool_manager, options)
  parts = args.split(' ', 2)
  subcommand = parts[0]
  task_description = parts[1]
  
  case subcommand
  when 'plan'
    if task_description.nil? || task_description.empty?
      puts "Usage: /agent plan <task description>"
      return
    end
    
    # Just create and show the plan
    task_analyzer = TaskAnalyzer.new
    planning_agent = PlanningAgent.new(provider_manager, tool_manager, task_analyzer: task_analyzer)
    
    puts "#{"\e[93m"}üìã Creating execution plan...#{"\e[0m"}"
    task = planning_agent.plan_task(task_description)
    
    puts "\n#{"\e[92m"}üìä Execution Plan:#{"\e[0m"}"
    puts task.to_tree_string
    
  when 'execute'
    if task_description.nil? || task_description.empty?
      puts "Usage: /agent execute <task description>"
      return
    end
    
    # Full agent execution
    execute_agent_task(task_description, provider_manager, tool_manager, options)
    
  when 'report'
    # Show task execution report
    task_database = TaskDatabase.new
    puts task_database.generate_optimization_report
    
  when 'history'
    # Show recent task history
    task_database = TaskDatabase.new
    recent_tasks = task_database.get_common_failures(10)
    
    puts "#{"\e[92m"}Recent Task History:#{"\e[0m"}"
    puts "-" * 50
    
    recent_tasks.each_with_index do |task, i|
      puts "#{i + 1}. #{task[:description][0..60]}#{'...' if task[:description].length > 60}"
      puts "   Failures: #{task[:failure_count]}"
      puts "   Issues: #{task[:common_issues].join(', ')}" if task[:common_issues].any?
      puts
    end
    
  when '', nil
    puts "Agent subcommands: plan, execute, report, history"
    puts "Example: /agent plan Create a REST API"
    
  else
    puts "Unknown agent subcommand: #{subcommand}"
    puts "Available: plan, execute, report, history"
  end
  
rescue => e
  puts "Agent command error: #{e.message}"
  puts e.backtrace.first(5).join("\n") if ENV['DEBUG']
end

def main
  options = {
    model: 'cogito:latest',
    provider: 'ollama',
    url: 'http://localhost:11434',
    region: 'us-east-1',
    secret: 'lantae/api-keys',
    temperature: 0.1,
    auto_accept: false,
    planning_mode: false,
    no_banner: false,
    enable_mcp: false,
    mcp_config: nil,
    agent_mode: false,
    enable_lsp: false
  }

  OptionParser.new do |opts|
    opts.banner = "Usage: #{$0} [options] [prompt]"
    
    opts.on('-m', '--model MODEL', 'Specify the model to use') { |v| options[:model] = v }
    opts.on('-p', '--provider PROVIDER', 'Specify the provider') { |v| options[:provider] = v }
    opts.on('-u', '--url URL', 'Ollama server URL') { |v| options[:url] = v }
    opts.on('-r', '--region REGION', 'AWS region') { |v| options[:region] = v }
    opts.on('-s', '--secret SECRET', 'AWS Secrets Manager secret name') { |v| options[:secret] = v }
    opts.on('-t', '--temperature TEMP', 'Temperature for responses') { |v| options[:temperature] = v.to_f }
    opts.on('-y', '--auto-accept', 'Auto-accept all prompts and confirmations') { options[:auto_accept] = true }
    opts.on('--planning-mode', 'Enable planning mode for complex tasks') { options[:planning_mode] = true }
    opts.on('--agent', 'Enable agent mode with task decomposition') { options[:agent_mode] = true }
    opts.on('--no-banner', 'Disable the startup banner') { options[:no_banner] = true }
    opts.on('--enable-mcp', 'Enable MCP (Model Context Protocol) support') { options[:enable_mcp] = true }
    opts.on('--mcp-config PATH', 'Path to MCP server configuration file') { |v| options[:mcp_config] = v }
    opts.on('--enable-lsp', 'Enable LSP (Language Server Protocol) for code intelligence') { options[:enable_lsp] = true }
    opts.on('--lsp-port PORT', 'LSP server port (default: 7777)') { |v| options[:lsp_port] = v.to_i }
    opts.on('-v', '--version', 'Show version') { puts VERSION; exit }
    opts.on('-h', '--help', 'Show this help') { puts opts; exit }
  end.parse!

  if ARGV.empty?
    start_repl(options)
  else
    send_single_prompt(ARGV.join(' '), options)
  end
end

if __FILE__ == $0
  main
end